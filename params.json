{"name":"Machinelearningcourseproject","tagline":"","body":"\r\n\r\n</head>\r\n\r\n<body>\r\n<p>In this document, I will detail how I created a model to determine the class of subjects in an exercise study. With this model, I was able to correctly predict the class of all 20 subjects in the test file. Since this model has an OOB (Out of bag) error of 2.36%, R predicts that this model will have a 97.64% accuracy on out of sample data, which is backed up by the 20/20 score on the test file.</p>\r\n\r\n<p>I chose my final model by:</p>\r\n\r\n<ol>\r\n<li><p>Keeping only the 50 most influential variables (found by creating a random forest model on all variables and using the varImp command)</p></li>\r\n<li><p>Removing any low variance variables (as defined by the nearZeroVar command)</p></li>\r\n<li><p>Keeping only 1 of highly correlated variables(i.e. correlation over .8, the most important variable as defined by varImp was kept)</p></li>\r\n<li><p>Removing any variables that were over 50% NAs, since these subjects would not be included in the final model by R anyway</p></li>\r\n</ol>\r\n\r\n<p>Variable choice:</p>\r\n\r\n<p>First, I partitioned the training data into training and testing sets:</p>\r\n\r\n<pre><code class=\"r\">library(caret)\r\ntrainingset &lt;-read.csv(&quot;training.csv&quot;,header = TRUE)\r\npart&lt;-createDataPartition(y=trainingset$classe,p=.8,list=FALSE)\r\ntrain1&lt;-trainingset[part,]\r\ntest1&lt;-trainingset[-part,]\r\n</code></pre>\r\n\r\n<p>I then used the training data to train a random forest model and determine the relative importance of each variable.I only kept the 50 most important variables.</p>\r\n\r\n<pre><code class=\"r\">train_rf2&lt;-train(classe~.,data=train1[,-1],method=&quot;rf&quot;,prox=TRUE)\r\n\r\ntrain_imp2&lt;-varImp(train_rf2,scale=FALSE)\r\n\r\n#gets 50 most important variables\r\nvarImportance&lt;-data.frame(train_imp2$importance)\r\nvarImportance$varnames&lt;-row.names(varImportance)\r\ntop50&lt;-varImportance[order(-varImportance$Overall),][1:50,]\r\n\r\n#only keep the top 50 variables\r\ndata_top50&lt;-train1[,which(names(train1) %in% top50$varnames)]\r\n#but add in name and classe since we need those for the analysis\r\ndata_top50&lt;-cbind(train1$user_name,train1$classe,data_top50)\r\n</code></pre>\r\n\r\n<p>I then looked at the remaining 50 variables&#39; variances and correlations, removing ones with extremely low variance or high correlation.</p>\r\n\r\n<pre><code class=\"r\">zerovar&lt;-nearZeroVar(data_top50,saveMetrics=TRUE)\r\n\r\ndata_top502&lt;-data_top50[,-nearZeroVar(data_top50)]\r\n</code></pre>\r\n\r\n<pre><code class=\"r\">#look at correlation\r\ndatacorr&lt;-cor(data_top502[,-c(1:2)],use=&quot;complete.obs&quot;)\r\n#adds varImp value to datacorr\r\ndatacorr&lt;-data.frame(datacorr)\r\ndatacorr$value&lt;-top50$Overall[match(row.names(datacorr),top50$varnames)]\r\ndatacorr2&lt;-abs(datacorr)\r\ntest.value &lt;- datacorr2$value\r\ndatacorr2 &lt;- datacorr2[,-ncol(datacorr2)]\r\n\r\n#this code determines if variables have a correlation above .8, and only keps the most important variable (as determined by the varImp function earlier) My thanks to Ilya Kashnitsky for his help creating this function.\r\nremove &lt;- c() \r\nfor(i in 1:ncol(datacorr2)){\r\n    coli &lt;- datacorr2[,i] \r\n    highcori &lt;- ifelse(coli&gt;=.8 &amp; coli!= 1, TRUE,FALSE) \r\n\r\n    if(sum(highcori,na.rm = T)&gt;0){\r\n\r\n        posi &lt;- which(highcori) \r\n\r\n        for(k in 1:length(posi)){\r\n            if(i!=k){\r\n                remi &lt;- ifelse(test.value[i]&gt;test.value[posi[k]],posi[k],i)\r\n                remove &lt;- c(remove,remi) \r\n            }\r\n        }\r\n    }\r\n\r\n}\r\n\r\nremove &lt;- sort(unique(remove)) \r\n\r\n#only include variables kept by above function\r\n#first add 2 to the remove variable, because the dataset has the name and class variables, while the correlation matrix does not\r\nremove&lt;-remove+2\r\ndata_top503&lt;-data_top502[,-remove]\r\n</code></pre>\r\n\r\n<p>Now lets look at the variables and see if there are any others that we might want to remove</p>\r\n\r\n<pre><code class=\"r\">colnames(data_top503)\r\n</code></pre>\r\n\r\n<pre><code>##  [1] &quot;train1$user_name&quot;      &quot;train1$classe&quot;        \r\n##  [3] &quot;raw_timestamp_part_1&quot;  &quot;num_window&quot;           \r\n##  [5] &quot;roll_belt&quot;             &quot;pitch_belt&quot;           \r\n##  [7] &quot;amplitude_roll_belt&quot;   &quot;stddev_roll_belt&quot;     \r\n##  [9] &quot;stddev_pitch_belt&quot;     &quot;magnet_belt_y&quot;        \r\n## [11] &quot;magnet_belt_z&quot;         &quot;var_accel_arm&quot;        \r\n## [13] &quot;magnet_arm_y&quot;          &quot;min_yaw_arm&quot;          \r\n## [15] &quot;amplitude_pitch_arm&quot;   &quot;min_roll_dumbbell&quot;    \r\n## [17] &quot;var_accel_dumbbell&quot;    &quot;avg_roll_dumbbell&quot;    \r\n## [19] &quot;avg_pitch_dumbbell&quot;    &quot;stddev_pitch_dumbbell&quot;\r\n## [21] &quot;var_yaw_dumbbell&quot;      &quot;gyros_dumbbell_y&quot;     \r\n## [23] &quot;accel_dumbbell_x&quot;      &quot;accel_dumbbell_y&quot;     \r\n## [25] &quot;magnet_dumbbell_x&quot;     &quot;magnet_dumbbell_y&quot;    \r\n## [27] &quot;magnet_dumbbell_z&quot;     &quot;pitch_forearm&quot;        \r\n## [29] &quot;var_accel_forearm&quot;     &quot;magnet_forearm_x&quot;\r\n</code></pre>\r\n\r\n<pre><code class=\"r\">#the &#39;raw_timestamp&#39; and &#39;num_window&#39; variables appear to be tracking variables, so can be removed from this analysis. \r\ndata_top503&lt;- data_top503[,-c(3:4)]\r\n#We&#39;ll also remove the user name variable, and rename the class variable\r\ndata_top503.1&lt;-data_top503[,-1]\r\ncolnames(data_top503.1)[1]&lt;-&quot;classe&quot;\r\n</code></pre>\r\n\r\n<p>Finally, I will remove all variables that are over 50% N/As, since they&#39;ll significantly reduce the number of complete observations that can be used in the model.</p>\r\n\r\n<pre><code class=\"r\">data_top503.1B&lt;-data_top503.1[,colSums(is.na(data_top503.1))&lt;(nrow(data_top503.1)*.5)]\r\n</code></pre>\r\n\r\n<p>Final Model:</p>\r\n\r\n<p>Now I will create a new random forest model, using only the 14 variables that have been chosen.</p>\r\n\r\n<pre><code class=\"r\">model&lt;-train(classe~., data=data_top503.1B,method=&quot;rf&quot;,prox=FALSE,ntrees=100)\r\n</code></pre>\r\n\r\n<p>As the confusion matrix below shows, this model does an excellent job of predicting the subject class in the test data (this is the test data that was partitioned from the training data, not the final test data). Note the predicted 2.36% OOB error rate.</p>\r\n\r\n<pre><code class=\"r\">#here are the names of the variables that ended up in this model\r\ncolnames(data_top503.1B)\r\n</code></pre>\r\n\r\n<pre><code>##  [1] &quot;classe&quot;            &quot;pitch_belt&quot;        &quot;magnet_belt_y&quot;    \r\n##  [4] &quot;magnet_belt_z&quot;     &quot;magnet_arm_y&quot;      &quot;gyros_dumbbell_y&quot; \r\n##  [7] &quot;accel_dumbbell_x&quot;  &quot;accel_dumbbell_y&quot;  &quot;magnet_dumbbell_x&quot;\r\n## [10] &quot;magnet_dumbbell_y&quot; &quot;magnet_dumbbell_z&quot; &quot;pitch_forearm&quot;    \r\n## [13] &quot;magnet_forearm_x&quot;\r\n</code></pre>\r\n\r\n<pre><code class=\"r\">model$finalModel\r\n</code></pre>\r\n\r\n<pre><code>## \r\n## Call:\r\n##  randomForest(x = x, y = y, mtry = param$mtry, proximity = FALSE,      ntrees = 100) \r\n##                Type of random forest: classification\r\n##                      Number of trees: 500\r\n## No. of variables tried at each split: 2\r\n## \r\n##         OOB estimate of  error rate: 2.36%\r\n## Confusion matrix:\r\n##      A    B    C    D    E class.error\r\n## A 4434    9    8   11    2  0.00672043\r\n## B   86 2890   46   15    1  0.04871626\r\n## C    1   41 2686    7    3  0.01899196\r\n## D   10    1   95 2461    6  0.04352895\r\n## E    0    8    5   15 2858  0.00970201\r\n</code></pre>\r\n\r\n<pre><code class=\"r\">pred&lt;-predict(model,newdata=test1)\r\n\r\nconfusionMatrix(pred,test1$classe)\r\n</code></pre>\r\n\r\n<pre><code>## Confusion Matrix and Statistics\r\n## \r\n##           Reference\r\n## Prediction    A    B    C    D    E\r\n##          A 1114    3    0    0    0\r\n##          B    2  756    1    0    1\r\n##          C    0    0  683    9    0\r\n##          D    0    0    0  634    1\r\n##          E    0    0    0    0  719\r\n## \r\n## Overall Statistics\r\n##                                           \r\n##                Accuracy : 0.9957          \r\n##                  95% CI : (0.9931, 0.9975)\r\n##     No Information Rate : 0.2845          \r\n##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \r\n##                                           \r\n##                   Kappa : 0.9945          \r\n##  Mcnemar&#39;s Test P-Value : NA              \r\n## \r\n## Statistics by Class:\r\n## \r\n##                      Class: A Class: B Class: C Class: D Class: E\r\n## Sensitivity            0.9982   0.9960   0.9985   0.9860   0.9972\r\n## Specificity            0.9989   0.9987   0.9972   0.9997   1.0000\r\n## Pos Pred Value         0.9973   0.9947   0.9870   0.9984   1.0000\r\n## Neg Pred Value         0.9993   0.9991   0.9997   0.9973   0.9994\r\n## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838\r\n## Detection Rate         0.2840   0.1927   0.1741   0.1616   0.1833\r\n## Detection Prevalence   0.2847   0.1937   0.1764   0.1619   0.1833\r\n## Balanced Accuracy      0.9986   0.9974   0.9979   0.9928   0.9986\r\n</code></pre>\r\n\r\n<p>I then predict the class of each subject in the final test data</p>\r\n\r\n<pre><code class=\"r\">finaltest&lt;-read.csv(&quot;test.csv&quot;,header=TRUE)\r\n\r\npred3&lt;-predict(model,finaltest)\r\n</code></pre>\r\n\r\n</body>\r\n\r\n</html>","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}